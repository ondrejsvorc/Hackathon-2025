{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d15595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, LayerNormalization, Dropout, Reshape, GlobalAveragePooling1D, MultiHeadAttention\n",
    "from loader import SingleFileExtractor, FolderExtractor, Segment  # <- Zde musí být tvůj loader\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "HDF_PATH = '/content/drive/MyDrive/data'\n",
    "SIGNAL_NAME = \"art\"\n",
    "WINDOW_SIZE = 500\n",
    "BATCH_SIZE = 64\n",
    "LATENT_DIM = 8\n",
    "EPOCHS = 5\n",
    "MODEL_DIR = \"models\"\n",
    "MAX_SAMPLES = 3600\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "class CreathonSegmentSequence(Sequence):\n",
    "    def __init__(self, segments, window_size=500, batch_size=64, normalize=True):\n",
    "        self.window_size = window_size\n",
    "        self.batch_size = batch_size\n",
    "        self.normalize = normalize\n",
    "        self.windows = []\n",
    "        self.data_mean = None\n",
    "        self.data_std = None\n",
    "\n",
    "        all_data = np.concatenate([seg.data for seg in segments if seg.data is not None and len(seg.data) >= window_size])\n",
    "        self.data_mean = np.nanmean(all_data)\n",
    "        self.data_std = np.nanstd(all_data) + 1e-8\n",
    "\n",
    "        for seg in segments:\n",
    "            if seg.data is None or len(seg.data) < window_size:\n",
    "                continue\n",
    "            data = seg.data\n",
    "            if normalize:\n",
    "                data = (data - self.data_mean) / self.data_std\n",
    "            for i in range(len(data) - window_size + 1):\n",
    "                window = data[i:i + window_size]\n",
    "                if np.isnan(window).any():\n",
    "                    continue\n",
    "                self.windows.append(window)\n",
    "\n",
    "        self.windows = np.array(self.windows)[..., np.newaxis]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.windows) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch = self.windows[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch, batch\n",
    "\n",
    "def get_file_paths(folder_path):\n",
    "    folder_extractor = FolderExtractor(folder_path)\n",
    "    return [e._hdf5_file_path for e in folder_extractor._extractors]\n",
    "\n",
    "def load_sequence_from_single_file(file_path, annotations_path, signal_name=\"icp\",\n",
    "                                   window_size=500, batch_size=64, use_anomalous=False):\n",
    "    extractor = SingleFileExtractor(file_path)\n",
    "    extractor.auto_annotate(annotations_path)\n",
    "\n",
    "    good, anom = extractor.extract(signal_name)\n",
    "    segments = good + anom if use_anomalous else good\n",
    "\n",
    "    limited_segments = []\n",
    "    total_samples = 0\n",
    "    for seg in segments:\n",
    "        if seg.data is None:\n",
    "            continue\n",
    "        if total_samples >= MAX_SAMPLES:\n",
    "            break\n",
    "        seg_length = len(seg.data)\n",
    "        if total_samples + seg_length > MAX_SAMPLES:\n",
    "            seg.data = seg.data[:MAX_SAMPLES - total_samples]\n",
    "        limited_segments.append(seg)\n",
    "        total_samples += len(seg.data)\n",
    "\n",
    "    extractor.load_data(limited_segments)\n",
    "    return CreathonSegmentSequence(limited_segments, window_size, batch_size)\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, sequence_length, d_model):\n",
    "        super().__init__()\n",
    "        self.pos_encoding = self.get_positional_encoding(sequence_length, d_model)\n",
    "\n",
    "    def get_positional_encoding(self, seq_len, d_model):\n",
    "        angle_rads = np.arange(seq_len)[:, np.newaxis] / np.power(10000, (2 * (np.arange(d_model)[np.newaxis, :] // 2)) / d_model)\n",
    "        pos_encoding = np.zeros((seq_len, d_model))\n",
    "        pos_encoding[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        pos_encoding[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        return tf.cast(pos_encoding[np.newaxis], dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        return x + self.pos_encoding[:, :tf.shape(x)[1], :]\n",
    "\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(dff, activation='relu'),\n",
    "            Dense(d_model)\n",
    "        ])\n",
    "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.drop1 = Dropout(dropout_rate)\n",
    "        self.drop2 = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        attn = self.att(x, x)\n",
    "        x = self.norm1(x + self.drop1(attn))\n",
    "        ffn = self.ffn(x)\n",
    "        return self.norm2(x + self.drop2(ffn))\n",
    "\n",
    "def build_transformer_autoencoder(window_size, latent_dim, d_model=64, num_heads=4, dff=128, num_layers=2):\n",
    "    inputs = Input(shape=(window_size, 1))\n",
    "    x = Dense(d_model)(inputs)\n",
    "    x = PositionalEncoding(window_size, d_model)(x)\n",
    "    for _ in range(num_layers):\n",
    "        x = TransformerBlock(d_model, num_heads, dff)(x)\n",
    "    latent = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(window_size * d_model)(latent)\n",
    "    x = Reshape((window_size, d_model))(x)\n",
    "    x = PositionalEncoding(window_size, d_model)(x)\n",
    "    for _ in range(num_layers):\n",
    "        x = TransformerBlock(d_model, num_heads, dff)(x)\n",
    "    outputs = Dense(1)(x)\n",
    "    return Model(inputs, outputs, name=\"transformer_autoencoder\")\n",
    "\n",
    "all_files = get_file_paths(HDF_PATH)\n",
    "sequence = load_sequence_from_single_file(\n",
    "    file_path=all_files[0],\n",
    "    annotations_path=HDF_PATH,\n",
    "    signal_name=SIGNAL_NAME,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    use_anomalous=False\n",
    ")\n",
    "\n",
    "autoencoder = build_transformer_autoencoder(WINDOW_SIZE, LATENT_DIM)\n",
    "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss=\"mse\")\n",
    "autoencoder.fit(sequence, epochs=EPOCHS)\n",
    "\n",
    "autoencoder.save(os.path.join(MODEL_DIR, \"transformer_autoencoder.keras\"))\n",
    "\n",
    "X, _ = sequence[0]\n",
    "recon = autoencoder.predict(X)\n",
    "X = X * sequence.data_std + sequence.data_mean\n",
    "recon = recon * sequence.data_std + sequence.data_mean\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(3):\n",
    "    plt.subplot(3, 2, i * 2 + 1)\n",
    "    plt.plot(X[i].squeeze(), label=\"Original\")\n",
    "    plt.legend()\n",
    "    plt.subplot(3, 2, i * 2 + 2)\n",
    "    plt.plot(recon[i].squeeze(), label=\"Reconstruction\")\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "latents = tf.random.normal((5, LATENT_DIM))\n",
    "x = autoencoder.layers[-3](latents)\n",
    "x = autoencoder.layers[-2](x)\n",
    "generated = autoencoder.layers[-1](x).numpy()\n",
    "generated = generated * sequence.data_std + sequence.data_mean\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.plot(generated[i].squeeze(), color='blue')\n",
    "    plt.title(f\"Syntetický signál {i+1}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
