{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1696798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import joblib\n",
    "from lib.loader import FolderExtractor, Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e24398d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Parametry ====\n",
    "HDF_PATH = \"data\"\n",
    "DATASET_PATH = \"waves/\"\n",
    "SIGNAL_NAME = \"icp\"\n",
    "MAX_SAMPLES = 36000\n",
    "WINDOW_SIZE = 500\n",
    "BATCH_SIZE = 64\n",
    "LATENT_DIM = 4\n",
    "EPOCHS = 20\n",
    "BETA = 1e-3  # KL váha\n",
    "MODEL_DIR = \"models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36dc7451",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreathonSegmentSequence(Sequence):\n",
    "    def __init__(self, segments, window_size=500, batch_size=64, normalize=True):\n",
    "        self.window_size = window_size\n",
    "        self.batch_size = batch_size\n",
    "        self.normalize = normalize\n",
    "        self.windows = []\n",
    "\n",
    "        for seg in segments:\n",
    "            if seg.data is None or len(seg.data) < window_size:\n",
    "                continue\n",
    "            data = seg.data\n",
    "            if normalize:\n",
    "                data = (data - np.nanmean(data)) / (np.nanstd(data) + 1e-8)\n",
    "\n",
    "            for i in range(len(data) - window_size + 1):\n",
    "                window = data[i:i + window_size]\n",
    "                if np.isnan(window).any():\n",
    "                    continue\n",
    "                self.windows.append(window)\n",
    "\n",
    "        self.windows = np.array(self.windows)[..., np.newaxis]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.windows) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch = self.windows[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch, batch\n",
    "\n",
    "def get_file_paths(folder_path):\n",
    "    folder_extractor = FolderExtractor(folder_path)\n",
    "    return [e._hdf5_file_path for e in folder_extractor._extractors]\n",
    "\n",
    "def load_sequence_from_single_file(file_path, annotations_path, signal_name=\"icp\",\n",
    "                                   window_size=500, batch_size=64, use_anomalous=False):\n",
    "    extractor = SingleFileExtractor(file_path)\n",
    "    extractor.auto_annotate(annotations_path)\n",
    "\n",
    "    good, anom = extractor.extract(signal_name)\n",
    "    segments = good + anom if use_anomalous else good\n",
    "    extractor.load_data(segments)\n",
    "\n",
    "    return CreathonSegmentSequence(segments, window_size, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "452d8262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sekvence\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_sequence_from_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33msekvence\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# ==== Trénování ====\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m sequence = \u001b[43mload_sequence_from_folder\u001b[49m(\n\u001b[32m     70\u001b[39m     folder_path=HDF_PATH,\n\u001b[32m     71\u001b[39m     signal_name=SIGNAL_NAME,\n\u001b[32m     72\u001b[39m     use_anomalous=\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# nebo True pokud chceš i anomální data\u001b[39;00m\n\u001b[32m     73\u001b[39m     window_size=\u001b[32m500\u001b[39m,\n\u001b[32m     74\u001b[39m     batch_size=\u001b[32m64\u001b[39m\n\u001b[32m     75\u001b[39m )\n\u001b[32m     76\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33msekvence done\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     77\u001b[39m encoder = build_encoder(LATENT_DIM)\n",
      "\u001b[31mNameError\u001b[39m: name 'load_sequence_from_folder' is not defined"
     ]
    }
   ],
   "source": [
    "# ==== Sampling layer ====\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# ==== Encoder ====\n",
    "def build_encoder(latent_dim):\n",
    "    inputs = layers.Input(shape=(WINDOW_SIZE, 1))\n",
    "    x = layers.Conv1D(16, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    z_mean = layers.Dense(latent_dim)(x)\n",
    "    z_log_var = layers.Dense(latent_dim)(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    return Model(inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "# ==== Decoder ====\n",
    "def build_decoder(latent_dim):\n",
    "    inputs = layers.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(500, activation=\"relu\")(inputs)\n",
    "    x = layers.Reshape((500, 1))(x)\n",
    "    x = layers.Conv1D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.Conv1D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.Conv1D(16, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.Conv1D(1, 3, padding=\"same\", activation=\"linear\")(x)\n",
    "    return Model(inputs, x, name=\"decoder\")\n",
    "\n",
    "# ==== VAE ====\n",
    "class VAE(Model):\n",
    "    def __init__(self, encoder, decoder, beta=1e-3):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.recon_loss_tracker = tf.keras.metrics.Mean(name=\"recon_loss\")\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    def compile(self, optimizer):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            recon_loss = tf.reduce_mean(tf.square(data - reconstruction))\n",
    "            kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            total_loss = recon_loss + self.beta * kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.recon_loss_tracker.update_state(recon_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"recon_loss\": self.recon_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "print(\"sekvence\")\n",
    "# ==== Trénování ====\n",
    "sequence = load_sequence_from_folder(\n",
    "    folder_path=HDF_PATH,\n",
    "    signal_name=SIGNAL_NAME,\n",
    "    use_anomalous=False,  # nebo True pokud chceš i anomální data\n",
    "    window_size=500,\n",
    "    batch_size=64\n",
    ")\n",
    "print(\"sekvence done\")\n",
    "encoder = build_encoder(LATENT_DIM)\n",
    "decoder = build_decoder(LATENT_DIM)\n",
    "print(\"enc a dec done\")\n",
    "vae = VAE(encoder, decoder, beta=BETA)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam(1e-3))\n",
    "vae.fit(sequence, epochs=EPOCHS)\n",
    "\n",
    "# ==== Uložení modelu ====\n",
    "encoder.save(os.path.join(MODEL_DIR, \"vae_encoder_hour.keras\"))\n",
    "decoder.save(os.path.join(MODEL_DIR, \"vae_decoder_hour.keras\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f320d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generation(n_samples=3):\n",
    "    random_latents = tf.random.normal((n_samples, LATENT_DIM))\n",
    "    generated = vae.decoder(random_latents).numpy()\n",
    "    \n",
    "    # Inverzní transformace\n",
    "    generated = generated * sequence.data_std + sequence.data_mean\n",
    "\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(1, n_samples, i + 1)\n",
    "        plt.plot(generated[i].squeeze())\n",
    "        plt.title(f\"Sample {i+1}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "def plot_reconstruction():\n",
    "    X, _ = sequence[0]\n",
    "    recon = vae.decoder(vae.encoder(X)[2]).numpy()\n",
    "\n",
    "    # Inverzní transformace\n",
    "    recon = recon * sequence.data_std + sequence.data_mean\n",
    "    X = X * sequence.data_std + sequence.data_mean\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(3):\n",
    "        plt.subplot(3, 2, i * 2 + 1)\n",
    "        plt.plot(X[i].squeeze(), label=\"Original\")\n",
    "        plt.legend()\n",
    "        plt.subplot(3, 2, i * 2 + 2)\n",
    "        plt.plot(recon[i].squeeze(), label=\"Reconstruction\")\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
